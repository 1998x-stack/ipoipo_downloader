"""
HTTPå®¢æˆ·ç«¯ - æ”¯æŒSessionä¿æŒå’Œé˜²ç›—é“¾ç»•è¿‡
"""
import time
import requests
from typing import Dict, Optional, Any
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from src.utils.logger import get_logger

logger = get_logger(__name__)


class HTTPClient:
    """
    HTTPå®¢æˆ·ç«¯ - ä½¿ç”¨Sessionä¿æŒcookieså’Œè¿æ¥çŠ¶æ€
    
    å…³é”®ç‰¹æ€§ï¼š
    1. ä½¿ç”¨ requests.Session ä¿æŒ cookiesï¼ˆé˜²ç›—é“¾ç»•è¿‡çš„å…³é”®ï¼‰
    2. æ”¯æŒä»£ç†é…ç½®
    3. è‡ªåŠ¨é‡è¯•æœºåˆ¶
    4. å®Œæ•´çš„æµè§ˆå™¨è¯·æ±‚å¤´æ¨¡æ‹Ÿ
    """
    
    # é»˜è®¤æµè§ˆå™¨è¯·æ±‚å¤´
    DEFAULT_HEADERS = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"macOS"',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
        'Cache-Control': 'max-age=0',
    }
    
    def __init__(self, use_proxy: bool = False, proxy_manager=None, 
                 proxy_url: str = None, timeout: int = 30, max_retries: int = 3):
        """
        åˆå§‹åŒ–HTTPå®¢æˆ·ç«¯
        
        Args:
            use_proxy: æ˜¯å¦ä½¿ç”¨ä»£ç†
            proxy_manager: ä»£ç†ç®¡ç†å™¨å®ä¾‹
            proxy_url: ç›´æ¥æŒ‡å®šä»£ç†URLï¼ˆå¦‚ "http://127.0.0.1:7890"ï¼‰
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.use_proxy = use_proxy
        self.proxy_manager = proxy_manager
        self.timeout = timeout
        self.max_retries = max_retries
        
        # ç”¨äºè·Ÿè¸ªæœ€åä¸€æ¬¡è¯·æ±‚çš„çŠ¶æ€ç 
        self._last_status_code = None
        
        # åˆ›å»º Session - å…³é”®ï¼ä¿æŒcookieså’Œè¿æ¥çŠ¶æ€
        self.session = requests.Session()
        
        # è®¾ç½®é»˜è®¤è¯·æ±‚å¤´
        self.session.headers.update(self.DEFAULT_HEADERS)
        
        # é…ç½®ä»£ç†
        if use_proxy:
            if proxy_url:
                # ç›´æ¥ä½¿ç”¨æŒ‡å®šçš„ä»£ç†URL
                self.session.proxies = {
                    'http': proxy_url,
                    'https': proxy_url
                }
                logger.info(f"ğŸ“¡ ä½¿ç”¨ä»£ç†: {proxy_url}")
            elif proxy_manager:
                # ä»ä»£ç†ç®¡ç†å™¨è·å–ä»£ç†
                proxy = proxy_manager.get_local_proxy()
                self.session.proxies = proxy
                logger.info(f"ğŸ“¡ ä½¿ç”¨ä»£ç†: {proxy}")
        
        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=max_retries,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "OPTIONS"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)
    
    def get(self, url: str, headers: Dict = None, **kwargs) -> requests.Response:
        """
        å‘é€GETè¯·æ±‚
        
        Args:
            url: è¯·æ±‚URL
            headers: é¢å¤–çš„è¯·æ±‚å¤´ï¼ˆä¼šä¸é»˜è®¤å¤´åˆå¹¶ï¼‰
            **kwargs: å…¶ä»–requestså‚æ•°
        """
        return self._request('GET', url, headers=headers, **kwargs)
    
    def head(self, url: str, headers: Dict = None, **kwargs) -> requests.Response:
        """å‘é€HEADè¯·æ±‚"""
        return self._request('HEAD', url, headers=headers, **kwargs)
    
    def post(self, url: str, headers: Dict = None, **kwargs) -> requests.Response:
        """å‘é€POSTè¯·æ±‚"""
        return self._request('POST', url, headers=headers, **kwargs)
    
    def _request(self, method: str, url: str, headers: Dict = None, 
                 **kwargs) -> requests.Response:
        """
        å‘é€è¯·æ±‚ï¼ˆå¸¦é‡è¯•ï¼‰
        
        Args:
            method: HTTPæ–¹æ³•
            url: è¯·æ±‚URL
            headers: é¢å¤–è¯·æ±‚å¤´
            **kwargs: å…¶ä»–å‚æ•°
        """
        # è®¾ç½®é»˜è®¤è¶…æ—¶
        kwargs.setdefault('timeout', self.timeout)
        
        # åˆå¹¶è¯·æ±‚å¤´
        request_headers = dict(self.session.headers)
        if headers:
            request_headers.update(headers)
        
        last_error = None
        for attempt in range(1, self.max_retries + 1):
            try:
                response = self.session.request(
                    method, url, headers=request_headers, **kwargs
                )
                response.raise_for_status()
                return response
                
            except requests.exceptions.HTTPError as e:
                last_error = e
                status_code = e.response.status_code if e.response else None
                
                if status_code == 403:
                    # 403é”™è¯¯ä¸é‡è¯•ï¼Œç›´æ¥è¿”å›è®©è°ƒç”¨è€…å¤„ç†
                    logger.warning(f"âš ï¸ è¯·æ±‚å¤±è´¥ (å°è¯• {attempt}/{self.max_retries}): "
                                 f"403 Client Error: Forbidden for url: {url}")
                    raise
                
                logger.warning(f"âš ï¸ è¯·æ±‚å¤±è´¥ (å°è¯• {attempt}/{self.max_retries}): {e}")
                
            except requests.exceptions.RequestException as e:
                last_error = e
                logger.warning(f"âš ï¸ è¯·æ±‚å¤±è´¥ (å°è¯• {attempt}/{self.max_retries}): {e}")
            
            # é‡è¯•å‰ç­‰å¾…
            if attempt < self.max_retries:
                time.sleep(2 ** attempt)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        logger.error(f"âŒ è¯·æ±‚å¤±è´¥,å·²é‡è¯• {self.max_retries} æ¬¡: {url}")
        raise last_error or requests.exceptions.RequestException(f"è¯·æ±‚å¤±è´¥: {url}")
    
    def download_file(self, url: str, save_path: str, referer: str = None,
                     chunk_size: int = 8192, timeout: int = 300) -> bool:
        """
        ä¸‹è½½æ–‡ä»¶ï¼ˆæ”¯æŒé˜²ç›—é“¾ç»•è¿‡ï¼‰
        
        Args:
            url: æ–‡ä»¶URL
            save_path: ä¿å­˜è·¯å¾„
            referer: Referer URLï¼ˆé˜²ç›—é“¾å…³é”®ï¼ï¼‰
            chunk_size: åˆ†å—å¤§å°
            timeout: ä¸‹è½½è¶…æ—¶
        
        Returns:
            æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        # é‡ç½®çŠ¶æ€ç 
        self._last_status_code = None
        
        # æ„å»ºä¸‹è½½è¯·æ±‚å¤´
        headers = self._get_download_headers(referer)
        
        logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½: {url}")
        if referer:
            logger.debug(f"ğŸ”— Referer: {referer}")
        
        try:
            response = self.session.get(
                url,
                headers=headers,
                stream=True,
                timeout=timeout,
                allow_redirects=True
            )
            
            # è®°å½•çŠ¶æ€ç ï¼ˆä¾›å¤–éƒ¨æ£€æŸ¥ï¼‰
            self._last_status_code = response.status_code
            
            # æ£€æŸ¥403é”™è¯¯
            if response.status_code == 403:
                logger.error(f"âŒ 403 Forbidden - é˜²ç›—é“¾æ‹¦æˆª!")
                tengine_error = response.headers.get('X-Tengine-Error', '')
                if tengine_error:
                    logger.error(f"   X-Tengine-Error: {tengine_error}")
                logger.error(f"   Referer: {referer}")
                return False
            
            response.raise_for_status()
            
            # éªŒè¯å†…å®¹ç±»å‹ï¼ˆé˜²æ­¢è¿”å›HTMLé”™è¯¯é¡µé¢ï¼‰
            content_type = response.headers.get('Content-Type', '')
            if 'text/html' in content_type.lower() and url.endswith('.zip'):
                logger.error(f"âŒ è¿”å›çš„æ˜¯HTMLè€Œä¸æ˜¯ZIPæ–‡ä»¶ï¼Œå¯èƒ½æ˜¯é˜²ç›—é“¾æ‹¦æˆª")
                self._last_status_code = 403  # æ ‡è®°ä¸º403
                return False
            
            # è·å–æ–‡ä»¶å¤§å°
            total_size = int(response.headers.get('Content-Length', 0))
            if total_size > 0:
                logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {total_size / 1024 / 1024:.2f} MB")
            
            # åˆ›å»ºç›®å½•
            import os
            os.makedirs(os.path.dirname(save_path) or '.', exist_ok=True)
            
            # åˆ†å—ä¸‹è½½
            downloaded = 0
            with open(save_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        
                        # æ˜¾ç¤ºè¿›åº¦
                        if total_size > 0 and downloaded % (chunk_size * 100) == 0:
                            progress = (downloaded / total_size) * 100
                            logger.debug(f"   ä¸‹è½½è¿›åº¦: {progress:.1f}%")
            
            logger.info(f"âœ… ä¸‹è½½å®Œæˆ: {save_path}")
            return True
            
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def _get_download_headers(self, referer: str = None) -> Dict[str, str]:
        """
        è·å–ä¸‹è½½è¯·æ±‚å¤´
        
        Args:
            referer: æ¥æºé¡µé¢URLï¼ˆé˜²ç›—é“¾å…³é”®ï¼‰
        """
        headers = {
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
        }
        
        if referer:
            headers['Referer'] = referer
            headers['Sec-Fetch-Site'] = 'cross-site'  # è·¨åŸŸè¯·æ±‚
        else:
            headers['Sec-Fetch-Site'] = 'none'
        
        return headers
    
    def get_cookies(self) -> Dict[str, str]:
        """è·å–å½“å‰sessionçš„cookies"""
        return dict(self.session.cookies)
    
    def get_last_status_code(self) -> Optional[int]:
        """è·å–æœ€åä¸€æ¬¡è¯·æ±‚çš„çŠ¶æ€ç """
        return self._last_status_code
    
    def clear_cookies(self):
        """æ¸…é™¤sessionçš„cookies"""
        self.session.cookies.clear()
    
    def close(self):
        """å…³é—­session"""
        self.session.close()
        logger.debug("ğŸ”’ HTTPå®¢æˆ·ç«¯å·²å…³é—­")


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    client = HTTPClient(use_proxy=False)
    
    try:
        # æµ‹è¯•æ™®é€šè¯·æ±‚
        response = client.get("https://httpbin.org/get")
        print(f"çŠ¶æ€ç : {response.status_code}")
        print(f"Cookies: {client.get_cookies()}")
    finally:
        client.close()