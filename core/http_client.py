"""
HTTPå®¢æˆ·ç«¯ - å¸¦ä»£ç†å’Œfake-headersæ”¯æŒ
"""
import time
import random
import requests
from typing import Optional, Dict
from fake_headers import Headers
from utils.logger import get_logger
from config.settings import (
    REQUEST_DELAY, MAX_RETRIES, RETRY_DELAY, 
    DOWNLOAD_TIMEOUT, USE_PROXY
)
from core.proxy_manager import ProxyManager

logger = get_logger(__name__)


class HTTPClient:
    """HTTPå®¢æˆ·ç«¯ï¼ˆæ”¯æŒä»£ç†å’Œfake-headersï¼‰"""
    
    def __init__(self, use_proxy: bool = USE_PROXY, proxy_manager: ProxyManager = None):
        self.use_proxy = use_proxy
        self.proxy_manager = proxy_manager
        self.session = requests.Session()
        self.headers_generator = Headers(headers=True)
        
        # é»˜è®¤headers
        self.default_headers = {
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
    
    def _get_headers(self) -> Dict[str, str]:
        """ç”Ÿæˆéšæœºheaders"""
        try:
            fake_headers = self.headers_generator.generate()
            headers = {**self.default_headers, **fake_headers}
            return headers
        except Exception as e:
            logger.warning(f"âš ï¸ ç”Ÿæˆfake-headerså¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤headers")
            return self.default_headers
    
    def _get_proxy(self) -> Optional[Dict[str, str]]:
        """è·å–ä»£ç†"""
        if not self.use_proxy or not self.proxy_manager:
            return None
        
        try:
            return self.proxy_manager.get_proxy(strategy="random")
        except Exception as e:
            logger.error(f"âŒ è·å–ä»£ç†å¤±è´¥: {e}")
            return None
    
    def _request_with_retry(self, method: str, url: str, **kwargs) -> requests.Response:
        """å¸¦é‡è¯•çš„è¯·æ±‚"""
        for attempt in range(1, MAX_RETRIES + 1):
            try:
                # æ·»åŠ éšæœºå»¶è¿Ÿ
                if attempt > 1:
                    delay = random.uniform(*REQUEST_DELAY)
                    logger.debug(f"â³ å»¶è¿Ÿ {delay:.1f}ç§’...")
                    time.sleep(delay)
                
                # å‡†å¤‡è¯·æ±‚å‚æ•°
                headers = kwargs.pop('headers', None) or self._get_headers()
                proxies = kwargs.pop('proxies', None) or self._get_proxy()
                timeout = kwargs.pop('timeout', DOWNLOAD_TIMEOUT)
                
                # å‘é€è¯·æ±‚
                logger.debug(f"ğŸŒ [{method.upper()}] {url} (å°è¯• {attempt}/{MAX_RETRIES})")
                response = self.session.request(
                    method=method,
                    url=url,
                    headers=headers,
                    proxies=proxies,
                    timeout=timeout,
                    **kwargs
                )
                
                response.raise_for_status()
                logger.debug(f"âœ… è¯·æ±‚æˆåŠŸ: {url} (çŠ¶æ€ç : {response.status_code})")
                return response
                
            except requests.exceptions.ProxyError as e:
                logger.warning(f"âš ï¸ ä»£ç†é”™è¯¯ (å°è¯• {attempt}/{MAX_RETRIES}): {e}")
                if self.proxy_manager and self.proxy_manager.current_node:
                    self.proxy_manager.mark_node_failed(self.proxy_manager.current_node)
                
            except requests.exceptions.Timeout as e:
                logger.warning(f"â±ï¸ è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt}/{MAX_RETRIES}): {e}")
                
            except requests.exceptions.RequestException as e:
                logger.warning(f"âš ï¸ è¯·æ±‚å¤±è´¥ (å°è¯• {attempt}/{MAX_RETRIES}): {e}")
                
            # é‡è¯•å‰ç­‰å¾…
            if attempt < MAX_RETRIES:
                wait_time = RETRY_DELAY * attempt
                logger.info(f"â³ ç­‰å¾… {wait_time}ç§’åé‡è¯•...")
                time.sleep(wait_time)
        
        raise RuntimeError(f"âŒ è¯·æ±‚å¤±è´¥ï¼Œå·²é‡è¯• {MAX_RETRIES} æ¬¡: {url}")
    
    def get(self, url: str, **kwargs) -> requests.Response:
        """GETè¯·æ±‚"""
        return self._request_with_retry('GET', url, **kwargs)
    
    def post(self, url: str, **kwargs) -> requests.Response:
        """POSTè¯·æ±‚"""
        return self._request_with_retry('POST', url, **kwargs)
    
    def download_file(self, url: str, save_path: str, resume: bool = True) -> bool:
        """ä¸‹è½½æ–‡ä»¶ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰"""
        from pathlib import Path
        import os
        
        save_path = Path(save_path)
        save_path.parent.mkdir(parents=True, exist_ok=True)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ–­ç‚¹ç»­ä¼ 
        if resume and save_path.exists():
            existing_size = save_path.stat().st_size
            headers = {'Range': f'bytes={existing_size}-'}
            mode = 'ab'
            logger.info(f"ğŸ“¥ æ–­ç‚¹ç»­ä¼ : {save_path.name} (å·²ä¸‹è½½ {existing_size} å­—èŠ‚)")
        else:
            existing_size = 0
            headers = {}
            mode = 'wb'
            logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½: {save_path.name}")
        
        try:
            # æ·»åŠ è‡ªå®šä¹‰headers
            request_headers = self._get_headers()
            request_headers.update(headers)
            
            response = self._request_with_retry(
                'GET', 
                url, 
                headers=request_headers,
                stream=True
            )
            
            # è·å–æ–‡ä»¶æ€»å¤§å°
            total_size = int(response.headers.get('content-length', 0)) + existing_size
            
            # æ£€æŸ¥æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
            if resume and existing_size > 0:
                if response.status_code != 206:
                    logger.warning("âš ï¸ æœåŠ¡å™¨ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œé‡æ–°ä¸‹è½½")
                    existing_size = 0
                    mode = 'wb'
            
            # ä¸‹è½½æ–‡ä»¶
            from tqdm import tqdm
            
            with open(save_path, mode) as f:
                with tqdm(total=total_size, initial=existing_size, unit='B', unit_scale=True) as pbar:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            pbar.update(len(chunk))
            
            logger.info(f"âœ… ä¸‹è½½å®Œæˆ: {save_path.name}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def close(self):
        """å…³é—­session"""
        self.session.close()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    from core.proxy_manager import ProxyManager
    
    pm = ProxyManager()
    pm.test_all_nodes()
    
    client = HTTPClient(use_proxy=True, proxy_manager=pm)
    
    try:
        response = client.get("https://ipoipo.cn")
        print(f"âœ… çŠ¶æ€ç : {response.status_code}")
        print(f"âœ… å†…å®¹é•¿åº¦: {len(response.text)}")
    finally:
        client.close()