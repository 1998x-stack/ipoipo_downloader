"""
ä¸‹è½½ç®¡ç†å™¨ - è´Ÿè´£ä¸‹è½½å’Œç®¡ç†ä¸‹è½½ä»»åŠ¡
"""
import os
from pathlib import Path
from typing import Optional, Dict
from concurrent.futures import ThreadPoolExecutor, as_completed
from utils.logger import get_logger
from core.http_client import HTTPClient
from core.database import Database
from download.file_manager import FileManager
from config.settings import MAX_CONCURRENT_DOWNLOADS

logger = get_logger(__name__)


class Downloader:
    """ä¸‹è½½ç®¡ç†å™¨"""
    
    def __init__(self, http_client: HTTPClient, database: Database, 
                 file_manager: FileManager):
        self.client = http_client
        self.db = database
        self.fm = file_manager
    
    def download_report(self, report: Dict, force: bool = False) -> bool:
        """ä¸‹è½½å•ä¸ªæŠ¥å‘Š"""
        post_id = report['post_id']
        title = report['title']
        category_id = report['category_id']
        download_url = report.get('download_url')
        
        logger.info(f"\n{'=' * 60}")
        logger.info(f"ğŸ“¥ ä¸‹è½½æŠ¥å‘Š: {title}")
        logger.info(f"{'=' * 60}")
        
        # æ£€æŸ¥æ˜¯å¦å·²ä¸‹è½½
        if not force and self.db.is_downloaded(post_id):
            logger.info(f"â­ï¸ å·²ä¸‹è½½ï¼Œè·³è¿‡: {title}")
            return True
        
        # æ£€æŸ¥ä¸‹è½½é“¾æ¥
        if not download_url:
            logger.error(f"âŒ æ²¡æœ‰ä¸‹è½½é“¾æ¥: {title}")
            self.db.update_report_status(post_id, 'no_download_url')
            return False
        
        try:
            # æå–æ–‡ä»¶å
            zip_filename = self._extract_filename(download_url, title)
            
            # è·å–ä¿å­˜è·¯å¾„
            zip_path = self.fm.get_zip_path(category_id, title, zip_filename)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            if zip_path.exists() and not force:
                file_size = self.fm.get_file_size(zip_path)
                logger.info(f"â­ï¸ æ–‡ä»¶å·²å­˜åœ¨: {zip_path.name} ({self.fm.format_size(file_size)})")
                
                # æ›´æ–°æ•°æ®åº“
                download_id = self.db.insert_download(post_id, download_url, zip_filename)
                self.db.update_download_status(
                    download_id, 'completed',
                    str(zip_path), file_size
                )
                self.db.update_report_status(post_id, 'downloaded')
                return True
            
            # åˆ›å»ºä¸‹è½½è®°å½•
            download_id = self.db.insert_download(post_id, download_url, zip_filename)
            
            # ä¸‹è½½æ–‡ä»¶
            logger.info(f"ğŸ”— ä¸‹è½½é“¾æ¥: {download_url}")
            logger.info(f"ğŸ’¾ ä¿å­˜è·¯å¾„: {zip_path}")
            
            success = self.client.download_file(
                download_url,
                str(zip_path),
                resume=True
            )
            
            if success:
                file_size = self.fm.get_file_size(zip_path)
                logger.info(f"âœ… ä¸‹è½½æˆåŠŸ: {self.fm.format_size(file_size)}")
                
                # æ›´æ–°æ•°æ®åº“
                self.db.update_download_status(
                    download_id, 'completed',
                    str(zip_path), file_size
                )
                self.db.update_report_status(post_id, 'downloaded')
                
                # è§£å‹æ–‡ä»¶
                self._extract_report(download_id, zip_path, title)
                
                return True
            else:
                logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {title}")
                self.db.update_download_status(
                    download_id, 'failed',
                    error_message="ä¸‹è½½å¤±è´¥"
                )
                return False
                
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½å‡ºé”™: {e}")
            try:
                self.db.update_download_status(
                    download_id, 'failed',
                    error_message=str(e)
                )
            except:
                pass
            return False
    
    def _extract_filename(self, url: str, title: str) -> str:
        """ä»URLæˆ–æ ‡é¢˜æå–æ–‡ä»¶å"""
        # å…ˆä»URLå°è¯•æå–
        parts = url.split('/')
        if parts:
            filename = parts[-1]
            if '.zip' in filename.lower():
                return filename
        
        # ä½¿ç”¨æ ‡é¢˜ä½œä¸ºæ–‡ä»¶å
        return self.fm.sanitize_filename(title) + '.zip'
    
    def _extract_report(self, download_id: int, zip_path: Path, title: str):
        """è§£å‹æŠ¥å‘Š"""
        try:
            logger.info(f"ğŸ“¦ å¼€å§‹è§£å‹...")
            
            # è§£å‹åˆ°åŒä¸€ç›®å½•
            extract_dir = self.fm.extract_zip(zip_path)
            
            if extract_dir:
                # ç»Ÿè®¡è§£å‹çš„æ–‡ä»¶
                extracted_files = self.fm.get_extracted_files(extract_dir)
                
                logger.info(f"âœ… è§£å‹æˆåŠŸ: {len(extracted_files)} ä¸ªæ–‡ä»¶")
                
                # è®°å½•åˆ°æ•°æ®åº“
                from core.database import Database
                self.db.conn.cursor().execute('''
                    INSERT INTO extractions (download_id, extract_path, files_count, status, extracted_at)
                    VALUES (?, ?, ?, 'completed', CURRENT_TIMESTAMP)
                ''', (download_id, str(extract_dir), len(extracted_files)))
                self.db.conn.commit()
                
                return True
            else:
                logger.error(f"âŒ è§£å‹å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"âŒ è§£å‹å‡ºé”™: {e}")
            return False
    
    def download_reports_by_category(self, category_id: str, 
                                     max_reports: int = None,
                                     force: bool = False):
        """ä¸‹è½½æŒ‡å®šåˆ†ç±»çš„æ‰€æœ‰æŠ¥å‘Š"""
        # è·å–åˆ†ç±»ä¸‹çš„æŠ¥å‘Š
        reports = self.db.get_reports_by_category(category_id, status='ready')
        
        if not reports:
            logger.warning(f"âš ï¸ åˆ†ç±» {category_id} æ²¡æœ‰å‡†å¤‡å¥½çš„æŠ¥å‘Š")
            return
        
        if max_reports:
            reports = reports[:max_reports]
        
        logger.info(f"ğŸ“Š å¾…ä¸‹è½½æŠ¥å‘Š: {len(reports)} ä¸ª")
        
        # ä¸‹è½½æŠ¥å‘Š
        success_count = 0
        fail_count = 0
        
        for i, report in enumerate(reports, 1):
            logger.info(f"\nè¿›åº¦: {i}/{len(reports)}")
            
            if self.download_report(report, force=force):
                success_count += 1
            else:
                fail_count += 1
        
        logger.info(f"\n{'=' * 60}")
        logger.info(f"âœ… ä¸‹è½½å®Œæˆï¼")
        logger.info(f"  - æˆåŠŸ: {success_count}")
        logger.info(f"  - å¤±è´¥: {fail_count}")
        logger.info(f"{'=' * 60}")
    
    def download_all_reports(self, max_reports: int = None,
                            force: bool = False,
                            use_concurrent: bool = False):
        """ä¸‹è½½æ‰€æœ‰å‡†å¤‡å¥½çš„æŠ¥å‘Š"""
        # è·å–æ‰€æœ‰å‡†å¤‡å¥½çš„æŠ¥å‘Š
        reports = []
        categories = self.db.get_all_categories()
        
        for category in categories:
            category_reports = self.db.get_reports_by_category(
                category['category_id'], 
                status='ready'
            )
            reports.extend(category_reports)
        
        if not reports:
            logger.warning("âš ï¸ æ²¡æœ‰å‡†å¤‡å¥½çš„æŠ¥å‘Š")
            return
        
        if max_reports:
            reports = reports[:max_reports]
        
        logger.info(f"ğŸ“Š å¾…ä¸‹è½½æŠ¥å‘Š: {len(reports)} ä¸ª")
        
        if use_concurrent:
            self._download_concurrent(reports, force)
        else:
            self._download_sequential(reports, force)
    
    def _download_sequential(self, reports: list, force: bool):
        """é¡ºåºä¸‹è½½"""
        success_count = 0
        fail_count = 0
        
        for i, report in enumerate(reports, 1):
            logger.info(f"\nè¿›åº¦: {i}/{len(reports)}")
            
            if self.download_report(report, force=force):
                success_count += 1
            else:
                fail_count += 1
        
        self._print_summary(success_count, fail_count)
    
    def _download_concurrent(self, reports: list, force: bool):
        """å¹¶å‘ä¸‹è½½"""
        success_count = 0
        fail_count = 0
        
        with ThreadPoolExecutor(max_workers=MAX_CONCURRENT_DOWNLOADS) as executor:
            futures = {
                executor.submit(self.download_report, report, force): report 
                for report in reports
            }
            
            for i, future in enumerate(as_completed(futures), 1):
                logger.info(f"\nè¿›åº¦: {i}/{len(reports)}")
                
                try:
                    if future.result():
                        success_count += 1
                    else:
                        fail_count += 1
                except Exception as e:
                    logger.error(f"âŒ ä¸‹è½½å¼‚å¸¸: {e}")
                    fail_count += 1
        
        self._print_summary(success_count, fail_count)
    
    def _print_summary(self, success: int, fail: int):
        """æ‰“å°ä¸‹è½½æ‘˜è¦"""
        logger.info(f"\n{'=' * 60}")
        logger.info(f"âœ… ä¸‹è½½å®Œæˆï¼")
        logger.info(f"  - æˆåŠŸ: {success}")
        logger.info(f"  - å¤±è´¥: {fail}")
        logger.info(f"{'=' * 60}")


if __name__ == "__main__":
    from core.proxy_manager import ProxyManager
    
    # åˆå§‹åŒ–
    pm = ProxyManager()
    pm.test_all_nodes()
    
    client = HTTPClient(use_proxy=True, proxy_manager=pm)
    db = Database()
    fm = FileManager()
    
    downloader = Downloader(client, db, fm)
    
    # æµ‹è¯•ï¼šä¸‹è½½å‰5ä¸ªæŠ¥å‘Š
    downloader.download_all_reports(max_reports=5)
    
    # æ˜¾ç¤ºç»Ÿè®¡
    stats = db.get_stats()
    print(f"\nğŸ“Š ç»Ÿè®¡:")
    print(f"  - ä¸‹è½½å®Œæˆ: {stats.get('downloads_completed', 0)}")
    print(f"  - ä¸‹è½½å¤±è´¥: {stats.get('downloads_failed', 0)}")
    
    client.close()
    db.close()